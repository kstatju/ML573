{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> ComS 573     </center></h1>\n",
    "<h1><center> Lab 2 </center></h1>\n",
    "<h1><center> Kanak Choudhury </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, I have used the following parameter combinations\n",
    "    \n",
    "    hidden_layers = [1,2,3]\n",
    "    hidden_units = [50, 64, 80]\n",
    "    num_epochs = [10, 50, 100]\n",
    "    btch_size = [128, 200, 300]\n",
    "    learning_rate = [0.1, 0.5, 0.9]\n",
    "    momentum = [.3, .5, 0.9]\n",
    "    loss_func = ['mean_squared_error', 'categorical_crossentropy']\n",
    "    data_scaling = ['Standardize', 'Normalize']\n",
    "    activation_func = ['relu']\n",
    "\n",
    "Also used 80% - 20% training - validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.1\n",
      "matplotlib 3.1.3\n",
      "keras 2.3.1\n",
      "re 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import matplotlib\n",
    "import keras\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "print('python ' +sys.version)\n",
    "print('numpy '+ np.__version__)\n",
    "print('pandas '+ pd.__version__)\n",
    "print('sklearn '+ sklearn.__version__)\n",
    "print('matplotlib '+ matplotlib.__version__)\n",
    "print('keras '+ keras.__version__)\n",
    "print('re '+ re.__version__)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = 'D:/ISU/COMS 573 - Machine Learning/HW/Lab2/'\n",
    "\n",
    "train_model = False\n",
    "\n",
    "df_tr = pd.read_csv(path+'optdigits.tra',header=None)\n",
    "X_tr, y_tr = df_tr.loc[:,0:63], df_tr.loc[:,64]\n",
    "ccat = y_tr.unique().size\n",
    "\n",
    "df_ts = pd.read_csv(path+'optdigits.tes',header=None)\n",
    "X_ts,  y_ts  = df_ts.loc[:,0:63],  df_ts.loc[:,64]\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "normalizer = Normalizer().fit(X_tr)\n",
    "\n",
    "X_tr_std = scaler.transform(X_tr)\n",
    "X_tr_norm = normalizer.transform(X_tr)\n",
    "\n",
    "\n",
    "split = 0.8\n",
    "size = np.shape(X_tr)\n",
    "nsplit = int(np.floor(split*size[0]))\n",
    "\n",
    "y_train1 = np_utils.to_categorical(y_tr, ccat)\n",
    "y_train = y_train1[0:nsplit,:];\n",
    "y_val = y_train1[nsplit:size[0],:];\n",
    "y_test = np_utils.to_categorical(y_ts, ccat)\n",
    "\n",
    "\n",
    "X_train_std = X_tr_std[0:nsplit,:];\n",
    "X_val_std = X_tr_std[nsplit:size[0],:];\n",
    "X_test_std = scaler.transform(X_ts)\n",
    "\n",
    "\n",
    "X_train_norm = X_tr_norm[0:nsplit,:];\n",
    "X_val_norm = X_tr_norm[nsplit:size[0],:];\n",
    "X_test_norm = normalizer.transform(X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skiped model fit\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    hidden_layers = [1,2,3]\n",
    "    hidden_units = [50, 64, 80]\n",
    "    num_epochs = [10, 50, 100]\n",
    "    btch_size = [128, 200, 300]\n",
    "    learning_rate = [0.1, 0.5, 0.9]\n",
    "    momentum = [.3, .5, 0.9]\n",
    "    loss_func = ['mean_squared_error', 'categorical_crossentropy']\n",
    "    data_scaling = ['Standardize', 'Normalize']\n",
    "    activation_func = ['relu']\n",
    "\n",
    "\n",
    "    def expand_grid(dictionary):\n",
    "       return pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "\n",
    "    dictionary = {'hidden_layers': hidden_layers,\n",
    "                  'hidden_units': hidden_units,\n",
    "                  'num_epochs': num_epochs, \n",
    "                  'batch_size': btch_size,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'momentum': momentum,\n",
    "                  'loss_func': loss_func,\n",
    "                  'data_scaling': data_scaling,\n",
    "                  'activation_func': activation_func}\n",
    "\n",
    "    prem = expand_grid(dictionary)\n",
    "    prem = prem[~((prem['activation_func'] == 'tanh') & (prem['loss_func'] == 'mean_squared_error'))]\n",
    "    prem['time'] = np.NaN\n",
    "    prem['train_loss'] = np.NaN\n",
    "    prem['validation_loss'] = np.NaN\n",
    "    prem['test_loss'] = np.NaN\n",
    "    prem['train_acc'] = np.NaN\n",
    "    prem['validation_acc'] = np.NaN\n",
    "    prem['test_acc'] = np.NaN\n",
    "    size_prem = prem.shape\n",
    "    print(prem.head())\n",
    "\n",
    "    ll = 0\n",
    "    for j in range(0,2):\n",
    "        if j == 0:\n",
    "            X_train = X_train_std\n",
    "            X_val = X_val_std\n",
    "            X_test = X_test_std\n",
    "            listind = prem[(prem['data_scaling'] == 'Standardize') & (prem.isnull().any(axis=1))].index.tolist()\n",
    "        else:\n",
    "            X_train = X_train_norm\n",
    "            X_val = X_val_norm\n",
    "            X_test = X_test_norm\n",
    "            listind = prem[(prem['data_scaling'] == 'Normalize') & (prem.isnull().any(axis=1))].index.tolist()\n",
    "\n",
    "        for i in listind:\n",
    "            start = time. time()\n",
    "            if prem.iloc[i,0] == 1:\n",
    "                model = Sequential()\n",
    "                model.add(Dense(prem.iloc[i,1], input_dim=64, activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "            elif prem.iloc[i,0] == 2:\n",
    "                model = Sequential()\n",
    "                model.add(Dense(prem.iloc[i,1], input_dim=64, activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(prem.iloc[i,1], activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "            elif prem.iloc[i,0] == 3:\n",
    "                model = Sequential()\n",
    "                model.add(Dense(prem.iloc[i,1], input_dim=64, activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(prem.iloc[i,1], activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(prem.iloc[i,1], activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "            else:\n",
    "                model = Sequential()\n",
    "                model.add(Dense(prem.iloc[i,1], input_dim=64, activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(prem.iloc[i,1], activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(prem.iloc[i,1], activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(prem.iloc[i,1], activation=prem.iloc[i,8]))\n",
    "                model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "            es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=200)\n",
    "            mc = ModelCheckpoint('best_model', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "\n",
    "            optimizer1 = optimizers.SGD(lr=prem.iloc[i,4], momentum=prem.iloc[i,5])\n",
    "            model.compile(optimizer=optimizer1, loss=prem.iloc[i,6], metrics=['accuracy'])\n",
    "            fit1 = model.fit(X_train,y_train, batch_size=prem.iloc[i,3], epochs=prem.iloc[i,2], \n",
    "                             validation_data=(X_val,y_val), callbacks=[es, mc], verbose = 0)\n",
    "            fit = load_model('best_model')\n",
    "            end = time.time()\n",
    "\n",
    "            train_accuracy = fit.evaluate(X_train, y_train, verbose=0)\n",
    "            val_accuracy = fit.evaluate(X_val, y_val, verbose=0)\n",
    "            test_accuracy = fit.evaluate(X_test, y_test, verbose=0)\n",
    "            prem.iloc[i, 9:16] = [end-start, train_accuracy[0], val_accuracy[0], test_accuracy[0], \n",
    "                                  train_accuracy[1], val_accuracy[1], test_accuracy[1]]\n",
    "\n",
    "            del model, es, mc, optimizer1, fit, fit1\n",
    "            gc.collect()\n",
    "            ll = ll+1\n",
    "            sys.stdout.write(\"\\r Progress: %.2f%%\" %round(float(ll)/size_prem[0]*100,2))\n",
    "            sys.stdout.flush()\n",
    "else:\n",
    "    print('skiped model fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best 10 hyper-parameter combination for Cross-Entropy:\n",
      "       hidden_layers  hiden_units  num_epochs  batch_size  learning_rate  \\\n",
      "1430              2           64          50         128            0.9   \n",
      "486               1           64          50         200            0.5   \n",
      "782               1           80          50         128            0.9   \n",
      "1290              2           50         100         300            0.9   \n",
      "1522              2           64         100         128            0.1   \n",
      "2766              3           80          50         200            0.9   \n",
      "2854              3           80         100         200            0.1   \n",
      "2823              3           80         100         128            0.5   \n",
      "1427              2           64          50         128            0.5   \n",
      "1571              2           64         100         200            0.5   \n",
      "\n",
      "      momentum                 loss_func data_scaling activation_func  \\\n",
      "1430       0.3  categorical_crossentropy  Standardize            relu   \n",
      "486        0.5  categorical_crossentropy  Standardize            relu   \n",
      "782        0.3  categorical_crossentropy  Standardize            relu   \n",
      "1290       0.5  categorical_crossentropy  Standardize            relu   \n",
      "1522       0.9  categorical_crossentropy  Standardize            relu   \n",
      "2766       0.5  categorical_crossentropy  Standardize            relu   \n",
      "2854       0.9  categorical_crossentropy  Standardize            relu   \n",
      "2823       0.3  categorical_crossentropy    Normalize            relu   \n",
      "1427       0.9  categorical_crossentropy    Normalize            relu   \n",
      "1571       0.9  categorical_crossentropy    Normalize            relu   \n",
      "\n",
      "         time  train_loss  validation_loss  test_loss  train_acc  \\\n",
      "1430   5.8781      0.0013           0.0781     0.1324     1.0000   \n",
      "486    5.0245      0.0110           0.0740     0.1119     0.9997   \n",
      "782    4.8596      0.0016           0.0455     0.1397     1.0000   \n",
      "1290   6.5375      0.0030           0.0699     0.1386     1.0000   \n",
      "1522   8.1272      0.0019           0.0760     0.1469     1.0000   \n",
      "2766   8.6308      0.0009           0.0869     0.1967     1.0000   \n",
      "2854  17.2453      0.0011           0.0811     0.1428     1.0000   \n",
      "2823  61.7760      0.0106           0.0743     0.1560     0.9974   \n",
      "1427  64.7441      0.0025           0.0735     0.1666     0.9997   \n",
      "1571  32.2653      0.0020           0.0926     0.1864     0.9997   \n",
      "\n",
      "      validation_acc  test_acc  \n",
      "1430          0.9869    0.9699  \n",
      "486           0.9817    0.9694  \n",
      "782           0.9882    0.9672  \n",
      "1290          0.9856    0.9672  \n",
      "1522          0.9830    0.9672  \n",
      "2766          0.9817    0.9672  \n",
      "2854          0.9843    0.9672  \n",
      "2823          0.9856    0.9666  \n",
      "1427          0.9869    0.9661  \n",
      "1571          0.9869    0.9661  \n",
      "\n",
      " Best 10 hyper-parameter combination for Mean-Squared-Error:\n",
      "       hidden_layers  hiden_units  num_epochs  batch_size  learning_rate  \\\n",
      "1432              2           64          50         128            0.9   \n",
      "1864              2           80         100         128            0.9   \n",
      "308               1           50         100         300            0.5   \n",
      "812               1           80          50         200            0.5   \n",
      "872               1           80         100         128            0.1   \n",
      "1508              2           64          50         300            0.9   \n",
      "464               1           64          50         128            0.9   \n",
      "1292              2           50         100         300            0.9   \n",
      "896               1           80         100         128            0.9   \n",
      "920               1           80         100         200            0.5   \n",
      "\n",
      "      momentum           loss_func data_scaling activation_func     time  \\\n",
      "1432       0.5  mean_squared_error  Standardize            relu   6.9287   \n",
      "1864       0.5  mean_squared_error  Standardize            relu  11.5742   \n",
      "308        0.9  mean_squared_error  Standardize            relu   5.8434   \n",
      "812        0.9  mean_squared_error  Standardize            relu   5.9002   \n",
      "872        0.9  mean_squared_error  Standardize            relu   8.8662   \n",
      "1508       0.9  mean_squared_error  Standardize            relu   5.5218   \n",
      "464        0.9  mean_squared_error  Standardize            relu   4.5238   \n",
      "1292       0.9  mean_squared_error  Standardize            relu  13.2303   \n",
      "896        0.9  mean_squared_error  Standardize            relu   8.1258   \n",
      "920        0.9  mean_squared_error  Standardize            relu   6.9174   \n",
      "\n",
      "      train_loss  validation_loss  test_loss  train_acc  validation_acc  \\\n",
      "1432      0.0006           0.0032     0.0055     0.9984          0.9817   \n",
      "1864      0.0002           0.0030     0.0054     0.9993          0.9856   \n",
      "308       0.0006           0.0035     0.0057     0.9977          0.9804   \n",
      "812       0.0008           0.0035     0.0054     0.9980          0.9843   \n",
      "872       0.0012           0.0041     0.0058     0.9964          0.9791   \n",
      "1508      0.0006           0.0038     0.0054     0.9971          0.9791   \n",
      "464       0.0007           0.0032     0.0055     0.9974          0.9830   \n",
      "1292      0.0004           0.0033     0.0055     0.9977          0.9817   \n",
      "896       0.0003           0.0034     0.0059     0.9987          0.9843   \n",
      "920       0.0008           0.0034     0.0057     0.9977          0.9843   \n",
      "\n",
      "      test_acc  \n",
      "1432    0.9666  \n",
      "1864    0.9661  \n",
      "308     0.9655  \n",
      "812     0.9655  \n",
      "872     0.9644  \n",
      "1508    0.9644  \n",
      "464     0.9638  \n",
      "1292    0.9638  \n",
      "896     0.9633  \n",
      "920     0.9633  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU5fn/8fdNgkQFgUK0Kgj6K7ViEkJY+xUEBcG6URQtFay0pSgWpNRatagFraLWDcXWUiugKG6ItbZYFEEEN0DiAlSrgBhsNYAgq2W5f3+ckzHEJHMimQwn+byua67McpZ7nsl85sxzzjzH3B0REYmfeukuQEREvh4FuIhITCnARURiSgEuIhJTCnARkZhSgIuIxJQCPObM7F4zu6aalnWUmW0xs4zw9jwzG1odyw6XN8vMLqyu5VVhvb8zs3Vm9t+aXrdIKinA92NmttrMtpvZZjPbaGYvm9nFZpZ43dz9Yne/PuKyelc2jbuvcfeG7r67Gmofa2bTyiz/e+4+dV+XXcU6WgKXAW3d/ZvlPN7TzIqqaV3V+oEnkowCfP93prs3AloBNwFXAH+p7pWYWWZ1L3M/0QpY7+6fpruQdKvFr3Hd5e667KcXYDXQu8x9nYE9QE54ewrwu/B6c+AZYCOwAXiJ4EP6wXCe7cAW4NdAa8CBnwJrgPml7ssMlzcPGA+8DmwC/gp8I3ysJ1BUXr3AqcD/gJ3h+t4stbyh4fV6wNXAh8CnwANA4/CxkjouDGtbB4yppJ0ah/MXh8u7Olx+7/A57wnrmFJmvoPLPL4FOCKc90rgA2A98Fip550FTAvv3wgsAg4DbgB2AzvC5UysoNbHgf+G7TkfOL7UYwcCt4XPYROwADgwfKwb8HK4zo+AIWXbNLw9BFhQ6rYDPwf+DawK75sQLuNzYAnQvdT0GcBvwue+OXy8JXAPcFuZ5/I34Bfpfp/U5UvaC9ClkhennAAP718DDA+vT+HLAB8P3AvUDy/dAStvWaVC8oEwyA6k/ABfC+SE08wApoWP9aSCAA+vjy2ZttTjibABfgK8DxwDNASeBB4sU9ufw7raAV8Ax1XQTg8QfLg0Cud9D/hpRXWWmbe85/EL4FWgBdAA+BMwPXzsojC4DgrDrgNwSNnnV8n6fhLW2QC4Eygs9dg94TKODJf9f+F0RxGE6Q/D17UZkF/eOik/wJ8DvsGXHwaDw2VkEnQv/RfICh+7HHgbOBawsO2bEWw4fAzUC6drDmwDDkv3+6QuX9SFEk8fE7why9oJHA60cved7v6Sh++2Sox1963uvr2Cxx9093fcfStwDXBeyU7OfTQIuN3dV7r7FuAqYGCZr/nj3H27u78JvEkQJnsJa/kBcJW7b3b31QRbsRfsQ20XEWzxF7n7FwQfRgPC2nYSBNq33H23uy9x98+jLtjd7w/rLFluOzNrHO7X+Akwyt3Xhst+OZxuEPC8u08PX9f17l5Yhecz3t03lLzG7j4tXMYud7+N4EPi2HDaocDV7v6uB94Mpy35FtYrnG4gMM/dP6lCHVLNFODxdCRBF0lZvyfYqp1tZivN7MoIy/qoCo9/SLAF2DxSlZU7Ilxe6WVnEnRHlCh91Mg2gi31spoDB5SzrCP3obZWwMxwx/FGYAVB98hhBN1R/wQeMbOPzewWM6sfZaFmlmFmN5nZB2b2OcE3lpLn0Jyge+aDcmZtWcH9Ue31GpvZZWa2wsw2hc+vMV++ppWtayrB1jvh3wf3oSapBgrwmDGzTgThtKDsY+GW3WXufgxwJvBLMyvZYqpoSzzZFnrLUtePItgCXQdsJehGKKkrA8iuwnI/JgjK0sveBVR1i25dWFPZZa2NOH95dX4EfM/dm5S6ZIVbxjvdfZy7tyXo4jgD+FElyyrtfKAfQd98Y4LuHgi6KtYR9J//vwrqKe9+KPM6AF850qZ0XWbWnWBH+HlAU3dvQrBlbRHWNQ3oZ2btgOOApyqYTmqIAjwmzOwQMzsDeISgb/ntcqY5w8y+ZWZGsINqd3iBIBiP+RqrHmxmbc3sIOA64AkPDjN8D8gys9PDLdCrCb6Kl/gEaF36kMcypgOjzexoM2sI3Ag86u67qlJcWMtjwA1m1sjMWgG/JAibKD4BmplZ41L33RsurxWAmWWbWb/w+klmlht+YH1O8OERtY0bEfTlrycI3RtLPY89wP3A7WZ2RLi1/l0zawA8BPQ2s/PMLNPMmplZfjhrIXC2mR1kZt8i2CldmUYEH5TFQKaZXQscUurx+4DrzayNBfLMrFlYYxHBTtsHgRmVdLtJDVGA7//+ZmabCbaMxgC3Az+uYNo2wPMER0G8AvzB3eeFj40Hrg67BX5VhfU/SLCj9L8EX/EvBXD3TcAlBG/4tQRbgqWPp348/LvezN4oZ7n3h8ueD6wi2PocWYW6ShsZrn8lwTeTh8PlJ+Xu/yL4MFkZts0RBEdpPE3QFbWZYIdml3CWbwJPEIT3CuBFvvywmEDQV/6Zmd1VzuoeIOjeWQssD5db2q8IdiAuIugiu5lgp+Ea4DSCHY4bCEK7ZH/AHQRH/HxC0MXxUJKn/E9gFsEH8IcE7V66i+V2gg/E2eFz/AvBjuQSU4Fc1H2yXyg5QkFEJCkzO5HgA6t1+K1B0khb4CISSdhVNgq4T+G9f1CAi0hSZnYcwY+IDic4fl32A+pCERGJKW2Bi4jEVEoGt2nevLm3bt06FYsWEamVlixZss7ds5NP+aWUBHjr1q1ZvHhxKhYtIlIrmdmHyafam7pQRERiSgEuIhJTCnARkZiqsTN07Ny5k6KiInbs2FFTqxRJyMrKokWLFtSvH2ngQJFYqLEALyoqolGjRrRu3ZpgrCWRmuHurF+/nqKiIo4++uh0lyNSbWqsC2XHjh00a9ZM4S01zsxo1qyZvv1JrVOjfeAKb0kX/e9JbaSdmCIiMVVjfeBl3fHce9W6vNGnfLtalycisr9LW4DL/qPkl7PNm1fHqS5FapG546s2/UlXpaaOCqgLpZbatatKZybbZ7t37670dkVquk6R2qTOBPjq1av5zne+w9ChQ8nJyWHQoEE8//zznHDCCbRp04bXX3+drVu38pOf/IROnTrRvn17/vrXvybm7d69OwUFBRQUFPDyyy8DMG/ePHr27MmAAQP4zne+w6BBg6hseN4rr7yStm3bkpeXx69+FZzVbNWqVXz3u9+lU6dOXHPNNTRs2DCx7DPOOCMx74gRI5gyZQoA1113HZ06dSInJ4dhw4Yl1tmzZ09+85vf0KNHDyZMmEBxcTHnnHMOnTp1olOnTixcuBCA9evX06dPH9q3b89FF11Uac0A06ZNo3PnzuTn53PRRRclwrlhw4Zce+21dOnShVdeeYXWrVtz3XXX0a1bNx5//HEKCwvp2rUreXl59O/fn88++6zcOkXk66kzAQ7w/vvvM2rUKN566y3+9a9/8fDDD7NgwQJuvfVWbrzxRm644QZOPvlkFi1axNy5c7n88svZunUrhx56KM899xxvvPEGjz76KJdeemlimUuXLuXOO+9k+fLlrFy5MhGSZW3YsIGZM2eybNky3nrrLa6++moARo0axfDhw1m0aBHf/GZ5JxT/qhEjRrBo0SLeeecdtm/fzjPPPJN4bOPGjbz44otcdtlljBo1itGjR7No0SJmzJjB0KFDARg3bhzdunVj6dKlnHXWWaxZs6bCda1YsYJHH32UhQsXUlhYSEZGBg89FJx2cevWreTk5PDaa6/RrVs3IPjBzIIFCxg4cCA/+tGPuPnmm3nrrbfIzc1l3Lhx5dYpIl9PneoDP/roo8nNzQXg+OOPp1evXpgZubm5rF69mqKiIp5++mluvfVWIDh2fc2aNRxxxBGMGDEiEWDvvfflDtjOnTvTokULAPLz81m9enUizEo75JBDyMrKYujQoZx++umJreuFCxcyY8YMAC644AKuuOKKpM9j7ty53HLLLWzbto0NGzZw/PHHc+aZZwLwgx/8IDHd888/z/LlyxO3P//8czZv3sz8+fN58sknATj99NNp2rRpheuaM2cOS5YsoVOnTgBs376dQw89FICMjAzOOeecvaYvWf+mTZvYuHEjPXr0AODCCy/k3HPP/cp0IvL11akAb9CgQeJ6vXr1Erfr1avHrl27yMjIYMaMGRx77LF7zTd27FgOO+ww3nzzTfbs2UNWVla5y8zIyKiwTzczM5PXX3+dOXPm8MgjjzBx4kReeOEFoPxjlDMzM9mz58vTDpb8CGXHjh1ccsklLF68mJYtWzJ27Ni9fqBy8MEHJ67v2bOHV155hQMPLH1ScSpcZ3ncnQsvvJDx47+6MycrK4uMjIy97iu9/spEnU5EKpa2AN8fD/vr27cvd999N3fffTdmxtKlS2nfvj2bNm2iRYsW1KtXj6lTp0beQVfali1b2LZtG6eddhpdu3blW9/6FgAnnHACjzzyCIMHD050TQC0atWK5cuX88UXX7Bjxw7mzJlDt27dEmHdvHlztmzZwhNPPMGAAQPKXWefPn2YOHEil19+OQCFhYXk5+dz4okn8tBDD3H11Vcza9asRN90eXr16kW/fv0YPXo0hx56KBs2bGDz5s20atWq0ufbuHFjmjZtyksvvUT37t158MEHE1vjIlI9IvWBm9loM1tmZu+Y2XQzy0o+V/xcc8017Ny5k7y8PHJycrjmmmsAuOSSS5g6dSpdu3blvffe+1pbj5s3b+aMM84gLy+PHj16cMcddwAwYcIE7rnnHjp16sSmTZsS07ds2ZLzzjuPvLw8Bg0aRPv27QFo0qQJP/vZz8jNzeX73/9+omujPHfddReLFy8mLy+Ptm3bcu+99wLw29/+lvnz51NQUMDs2bM56qijKlxG27Zt+d3vfkefPn3Iy8vjlFNO4T//+U+k5zx16lQuv/xy8vLyKCws5Nprr400n4hEk/SkxmZ2JLAAaOvu283sMeAf7j6lonk6duzoZc/Is2LFCo477rh9r7iWa9iwIVu2bEl3GbWS/gelymrwOHAzW+LuHasyT9SjUDKBA80sEzgI+LiqxYmISPVK2gfu7mvN7FZgDbAdmO3us8tOZ2bDgGFApV/J64L+/fuzatWqve67+eab6du3b9J507X1vX79enr16vWV++fMmUOzZs3SUJGIJJM0wM2sKdAPOBrYCDxuZoPdfVrp6dx9EjAJgi6UFNQaGzNnzkx3CVXWrFkzCgsL012GiFRBlC6U3sAqdy92953Ak8D/pbYsERFJJkqArwG6mtlBFhw83AtYkdqyREQkmaQB7u6vAU8AbwBvh/NMSnFdIiKSRKQf8rj7b4HfVuuaq3p4TjI1PIyjiEi61anBrKKaN29eYsTBVDvttNPYuHFjleebMmUKI0aMSEFFqXfjjTemuwSRWkEBXo6aCHB3Z8+ePfzjH/+gSZMmKV1XZetPh4oCPJ01icRRnQrwBx54gLy8PNq1a8cFF1zA3/72N7p06UL79u3p3bs3n3zyCatXr+bee+/ljjvuID8/n5deeqnCcbWLi4s55ZRTKCgo4KKLLqJVq1asW7cOgNtvv52cnBxycnK48847gWBc8eOOO45LLrmEgoICPvroI1q3bp2Yp2x9QLk1RvHJJ5/Qv39/2rVrR7t27Xj55ZfLXf/06dPJzc0lJycnMRLi7t27GTJkCDk5OeTm5iZ+9n/XXXclxjMfOHAgQIVjqE+ZMoWzzz6bU089lTZt2vDrX/8aCMZE3759O/n5+QwaNChyTRD8SvWyyy6joKCAXr16UVxczAcffEBBQUFimn//+9906NDha/x3iMRPnRmNcNmyZdxwww0sXLiQ5s2bs2HDBsyMV199FTPjvvvu45ZbbuG2227j4osvpmHDhomTLpx//vmMHj2abt26sWbNGvr27cuKFSsYN24cJ598MldddRXPPvsskyYF+3aXLFnC5MmTee2113B3unTpQo8ePWjatCnvvvsukydP5g9/+EPS+gC6detWbo3JXHrppfTo0YOZM2eye/dutmzZwmeffbbX+j/++GOuuOIKlixZQtOmTenTpw9PPfUULVu2ZO3atbzzzjsAiS6em266iVWrVtGgQYPEfSVjqN9///1s3LiRzp0707t3byAYPGvp0qU0aNCAY489lpEjR3LTTTcxceLExDHnq1evjlTT97//fbZu3UpBQQG33XYb1113HePGjWPixIk0btw4MVDX5MmTGTJkyD7+t4jEQ53ZAn/hhRcYMGBA4ryP3/jGNygqKqJv377k5uby+9//nmXLlpU77/PPP8+IESPIz8/nrLPOSoyrXXLiAoBTTz01Ma72ggUL6N+/PwcffDANGzbk7LPP5qWXXgKCUQa7du0aqT4gco3lLW/48OFAMMxt48aNv7L+RYsW0bNnT7Kzs8nMzGTQoEHMnz+fY445hpUrVzJy5EieffZZDjnkEIDEwFrTpk0jMzP47J89ezY33XQT+fn59OzZMzGGOgQjGTZu3JisrCzatm3Lhx9+WG6tUWqCYNjfknHEBw8ezIIFCwAYOnQokydPZvfu3Tz66KOcf/75kdpIJO7qTIC7+1fGwB45ciQjRozg7bff5k9/+tNe42qXVjKudmFhIYWFhaxdu5ZGjRpVeCqyygYIq2gkw/Lqq0qNUZVef0V1Nm3alDfffJOePXtyzz33JM7k8/e//52f//znLFmyhA4dOrBr1y7cnRkzZiTaZs2aNYkBo6KOlR6lpvKUtNc555zDrFmzeOaZZ+jQoYN++i91RvoC/KSrqveSRK9evXjsscdYv349EJzibNOmTRx55JFAMPRpiUaNGrF58+bE7ZJxtUuUfP3v1q0bjz32GBBsiZaMq33iiSfy1FNPsW3bNrZu3crMmTPp3r17lesDKqwxyvP94x//CAR92p9//vlXpunSpQsvvvgi69atY/fu3UyfPp0ePXqwbt069uzZwznnnMP111/PG2+8wZ49e/joo4846aSTuOWWW9i4cSNbtmxJjKFeErxLly5NWlv9+vXZuXNnuY9VVBMEH6RPPPEEAA8//PBep3Hr27cvw4cP58c//nHkNhKJuzqzBX788cczZswYevToQbt27fjlL3/J2LFjOffcc+nevXui6wLgzDPPZObMmYmdmJWNqz179mwKCgqYNWsWhx9+OI0aNaKgoIAhQ4bQuXNnunTpwtChQxPjeVelPqDCGpOZMGECc+fOJTc3lw4dOpTb9XL44Yczfvx4TjrpJNq1a0dBQQH9+vVj7dq19OzZk/z8fIYMGcL48ePZvXs3gwcPJjc3l/bt2zN69GiaNGlS4RjqlRk2bFiiOyZqTRBsqS9btowOHTrwwgsv7DW++KBBgzAz+vTpE7mNROIu6XjgX0ddGQ/8iy++ICMjg8zMTF555RWGDx+uAaFSqLKx0m+99VY2bdrE9ddfX+H8tfF/UFJsPx8PvM4chZIKa9as4bzzzmPPnj0ccMAB/PnPf053SXVS//79+eCDDxLnGBWpKxTg+6BNmzaR+nxT6YYbbuDxxx/f675zzz2XMWPGpKmi1Klo6zuOw/eKVIcaDfCKjrSQr2/MmDG1MqyrWyq6CkXSrcZ2YmZlZbF+/Xq9kaTGuTvr168nK6tWnotb6rAa2wJv0aIFRUVFFBcX19QqRRKysrJo0aJFussQqVY1FuD169fn6KOPrqnViYjUekm7UMzsWDMrLHX53Mx+URPFiYhIxaKclf5dIB/AzDKAtYB2+4uIpFlVd2L2Aj5w9/JHJRIRkRpT1QAfCExPRSEiIlI1kQPczA4AzgIer+DxYWa22MwW60gTEZHUq8oW+PeAN9y93FPCuPskd+/o7h2zs7OrpzoREalQVQL8h6j7RERkvxEpwM3sIOAU4MnUliMiIlFF+iGPu28DdJoTEZH9SJ05oYOISG2jABcRiSkFuIhITCnARURiSgEuIhJTCnARkZhSgIuIxJQCXEQkphTgIiIxpQAXEYkpBbiISEwpwEVEYkoBLiISUwpwEZGYUoCLiMRUpPHARUTi7o7n3qvyPKP384SMekaeJmb2hJn9y8xWmNl3U12YiIhULurnywTgWXcfEJ6d/qAU1iQiIhEkDXAzOwQ4ERgC4O7/A/6X2rJERCSZKF0oxwDFwGQzW2pm95nZwWUnMrNhZrbYzBYXFxdXe6EiIrK3KAGeCRQAf3T39sBW4MqyE7n7JHfv6O4ds7Ozq7lMEREpK0qAFwFF7v5aePsJgkAXEZE0Shrg7v5f4CMzOza8qxewPKVViYhIUlGPQhkJPBQegbIS+HHqShIRkSgiBbi7FwIdU1yLiIhUgX5KLyISUwpwEZGYUoCLiMSUAlxEJKYU4CIiMaUAFxGJKQW4iEhMKcBFRGJKAS4iElMKcBGRmFKAi4jElAJcRCSmFOAiIjGlABcRiSkFuIhITCnARURiKtIJHcxsNbAZ2A3scned3EFEJM2inlIN4CR3X5eySkREpErUhSIiElNRA9yB2Wa2xMyGlTeBmQ0zs8Vmtri4uLj6KhQRkXJFDfAT3L0A+B7wczM7sewE7j7J3Tu6e8fs7OxqLVJERL4qUoC7+8fh30+BmUDnVBYlIiLJJQ1wMzvYzBqVXAf6AO+kujAREalclKNQDgNmmlnJ9A+7+7MprUpERJJKGuDuvhJoVwO1iIhIFegwQhGRmFKAi4jElAJcRCSmFOAiIjGlABcRiSkFuIhITCnARURiSgEuIhJTCnARkZhSgIuIxJQCXEQkphTgIiIxpQAXEYkpBbiISEwpwEVEYipygJtZhpktNbNnUlmQiIhEU5Ut8FHAilQVIiIiVRMpwM2sBXA6cF9qyxERkaiiboHfCfwa2FPRBGY2zMwWm9ni4uLiailOREQqFuWs9GcAn7r7ksqmc/dJ7t7R3TtmZ2dXW4EiIlK+KFvgJwBnmdlq4BHgZDObltKqREQkqaQB7u5XuXsLd28NDARecPfBKa9MREQqpePARURiKrMqE7v7PGBeSioREZEq0Ra4iEhMKcBFRGJKAS4iElMKcBGRmFKAi4jElAJcRCSmFOAiIjGlABcRiSkFuIhITCnARURiSgEuIhJTCnARkZhSgIuIxJQCXEQkphTgIiIxpQAXEYmpKCc1zjKz183sTTNbZmbjaqIwERGpXJQz8nwBnOzuW8ysPrDAzGa5+6sprk1ERCqRNMDd3YEt4c364cVTWZSIiCQXqQ/czDLMrBD4FHjO3V8rZ5phZrbYzBYXFxdXd50iIlJGpAB3993ung+0ADqbWU4500xy947u3jE7O7u66xQRkTKqdBSKu28kOCv9qSmpRkREIotyFEq2mTUJrx8I9Ab+lerCRESkclGOQjkcmGpmGQSB/5i7P5PaskREJJkoR6G8BbSvgVpERKQK9EtMEZGYUoCLiMSUAlxEJKYU4CIiMaUAFxGJKQW4iEhMKcBFRGJKAS4iElMKcBGRmFKAi4jElAJcRCSmFOAiIjGlABcRiSkFuIhITCnARURiKsoZeVqa2VwzW2Fmy8xsVE0UJiIilYtyRp5dwGXu/oaZNQKWmNlz7r48xbWJiEglkm6Bu/t/3P2N8PpmYAVwZKoLExGRylWpD9zMWhOcXu21VBQjIiLRRQ5wM2sIzAB+4e6fl/P4MDNbbGaLi4uLq7NGEREpR6QAN7P6BOH9kLs/Wd407j7J3Tu6e8fs7OzqrFFERMoR5SgUA/4CrHD321NfkoiIRBFlC/wE4ALgZDMrDC+npbguERFJIulhhO6+ALAaqEVERKpAv8QUEYkpBbiISEwpwEVEYkoBLiISUwpwEZGYUoCLiMSUAlxEJKYU4CIiMaUAFxGJKQW4iEhMKcBFRGJKAS4iElMKcBGRmFKAi4jElAJcRCSmFOAiIjEV5ZRq95vZp2b2Tk0UJCIi0UTZAp8CnJriOkREpIqSBri7zwc21EAtIiJSBdXWB25mw8xssZktLi4urq7FiohIBaotwN19krt3dPeO2dnZ1bVYERGpgI5CERGJKQW4iEhMRTmMcDrwCnCsmRWZ2U9TX5aIiCSTmWwCd/9hTRQiIiJVoy4UEZGYSroFLrXfHc+9V6XpR5/y7RRVIiJVoS1wEZGY0ha4pJW2/uuWqr7eoNe8MtoCFxGJKQW4iEhMqQtlP6GuhJqnr/MSd9oCFxGJKQW4iEhMqQulFHVjSF2grqPaI/4BPnd81ec56arqr0NEUqOq7/E69P5WF4qISEzFfwtcJIbUjSHVQQEeV3W166iuPu90UzfGfkkBLlWnEBXZLyjA94WCrO5J55aotoKljEgBbmanAhOADOA+d78pVQVV+VA+fQSJSB0V5ZRqGcA9wPeAtsAPzaxtqgsTEZHKRTmMsDPwvruvdPf/AY8A/VJbloiIJGPuXvkEZgOAU919aHj7AqCLu48oM90wYFh481jg3QoW2RxYty9F1wJqA7UBqA1AbQBftkErd8+uyoxRepCtnPu+kvruPgmYlHRhZovdvWOE9dZaagO1AagNQG0A+9YGUbpQioCWpW63AD7+OisTEZHqEyXAFwFtzOxoMzsAGAg8ndqyREQkmaRdKO6+y8xGAP8kOIzwfndftg/rTNrNUgeoDdQGoDYAtQHsQxsk3YkpIiL7J41GKCISUwpwEZGYSkmAm9mpZvaumb1vZleW83gDM3s0fPw1M2udijrSKUIb/NLMlpvZW2Y2x8xapaPOVEvWDqWmG2Bmbma17pCyKG1gZueF/w/LzOzhmq4x1SK8H44ys7lmtjR8T5yWjjpTxczuN7NPzeydCh43M7srbJ+3zKwg0oLdvVovBDs6PwCOAQ4A3gTalpnmEuDe8PpA4NHqriOdl4htcBJwUHh9eG1rg6jtEE7XCJgPvAp0THfdafhfaAMsBZqGtw9Nd91paINJwPDweltgdbrrruY2OBEoAN6p4PHTgFkEv7vpCrwWZbmp2AKP8tP7fsDU8PoTQC8zK+8HQ3GVtA3cfa67bwtvvkpwfH1tE3UYhuuBW4AdNVlcDYnSBj8D7nH3zwDc/dMarjHVorSBA4eE1xtTy35r4u7zgQ2VTNIPeMADrwJNzOzwZMtNRYAfCXxU6nZReF+507j7LmAT0CwFtaRLlDYo7WyJAwIAAAH6SURBVKcEn761TdJ2MLP2QEt3f6YmC6tBUf4Xvg1828wWmtmr4eiftUmUNhgLDDazIuAfwMiaKW2/UdXMAFIzHniUn95H+nl+jEV+fmY2GOgI9EhpRelRaTuYWT3gDmBITRWUBlH+FzIJulF6EnwTe8nMctx9Y4prqylR2uCHwBR3v83Mvgs8GLbBntSXt1/4WpmYii3wKD+9T0xjZpkEX5kq+3oRN5GGHzCz3sAY4Cx3/6KGaqtJydqhEZADzDOz1QR9f0/Xsh2ZUd8Pf3X3ne6+imAguDY1VF9NiNIGPwUeA3D3V4AsgkGe6oqvNWRJKgI8yk/vnwYuDK8PAF7wsCe/lkjaBmHXwZ8Iwru29XmWqLQd3H2Tuzd399bu3ppgX8BZ7r44PeWmRJT3w1MEO7Uxs+YEXSora7TK1IrSBmuAXgBmdhxBgBfXaJXp9TTwo/BolK7AJnf/T9K5UrTH9TTgPYI9z2PC+64jeHNC8OI8DrwPvA4ck+69xGlog+eBT4DC8PJ0umtORzuUmXYetewolIj/CwbcDiwH3gYGprvmNLRBW2AhwREqhUCfdNdczc9/OvAfYCfB1vZPgYuBi0v9D9wTts/bUd8H+im9iEhM6ZeYIiIxpQAXEYkpBbiISEwpwEVEYkoBLiISUwpwEZGYUoCLiMTU/wfsWZVjtFFdJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train_model:\n",
    "    prem.to_csv (path+'res_1a.csv', index = False, header=True)\n",
    "else:\n",
    "    prem = pd.read_csv(path+'res_1a.csv',header=0)\n",
    "    prem.head(15)\n",
    "\n",
    "top10_mse = prem[prem['loss_func'] == 'mean_squared_error'].nlargest(10,'test_acc')\n",
    "top10_cce = prem[prem['loss_func'] == 'categorical_crossentropy'].nlargest(10,'test_acc')\n",
    "print('\\n Best 10 hyper-parameter combination for Cross-Entropy:\\n', round(top10_cce, 4))\n",
    "print('\\n Best 10 hyper-parameter combination for Mean-Squared-Error:\\n', round(top10_mse, 4))\n",
    "\n",
    "plt.hist([prem[prem['loss_func'] == 'mean_squared_error'].iloc[:,9], \n",
    "          prem[prem['loss_func'] == 'categorical_crossentropy'].iloc[:,9]], \n",
    "         bins=300, density=True, alpha=0.5, label=['mean_squared_error', 'categorical_crossentropy'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of time to fit models')\n",
    "plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.hist([prem[prem['loss_func'] == 'mean_squared_error'].iloc[:,15], \n",
    "          prem[prem['loss_func'] == 'categorical_crossentropy'].iloc[:,15]], \n",
    "         density=True, alpha=0.5, label=['mean_squared_error', 'categorical_crossentropy'])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Distribution of test accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and Variance of fitted time:\n",
      " mean_squared_error: Mean = 30.62, var = 18043.78\n",
      " categorical_crossentropy: Mean = 37.11, var = 70030.07\n",
      "\n",
      "Mean and Variance of test accuracy:\n",
      " mean_squared_error: Mean = 0.7483, var = 0.0726\n",
      " categorical_crossentropy: Mean = 0.8520, var = 0.0515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aaa = prem[prem['loss_func'] == 'mean_squared_error'].iloc[:,9]\n",
    "bbb = prem[prem['loss_func'] == 'categorical_crossentropy'].iloc[:,9]\n",
    "print(\"Mean and Variance of fitted time:\\n mean_squared_error: Mean = %.2f, \\\n",
    "var = %.2f\\n categorical_crossentropy: Mean = %.2f, \\\n",
    "var = %.2f\\n\" %(np.mean(aaa), np.var(aaa), np.mean(bbb), np.var(bbb)))\n",
    "\n",
    "aaa = prem[prem['loss_func'] == 'mean_squared_error'].iloc[:,15]\n",
    "bbb = prem[prem['loss_func'] == 'categorical_crossentropy'].iloc[:,15]\n",
    "print(\"Mean and Variance of test accuracy:\\n mean_squared_error: Mean = %.4f, \\\n",
    "var = %.4f\\n categorical_crossentropy: Mean = %.4f, \\\n",
    "var = %.4f\\n\" %(np.mean(aaa), np.var(aaa), np.mean(bbb), np.var(bbb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results For Cross-Entropy\n",
      "**********************************\n",
      "\n",
      "For hyper-parameters:\n",
      " hidden_layers                             2\n",
      "hiden_units                              64\n",
      "num_epochs                               50\n",
      "batch_size                              128\n",
      "learning_rate                           0.9\n",
      "momentum                                0.3\n",
      "loss_func          categorical_crossentropy\n",
      "data_scaling                    Standardize\n",
      "activation_func                        relu\n",
      "time                                5.87814\n",
      "train_loss                       0.00131139\n",
      "validation_loss                   0.0780658\n",
      "test_loss                          0.132371\n",
      "train_acc                                 1\n",
      "validation_acc                     0.986928\n",
      "test_acc                            0.96995\n",
      "Name: 1430, dtype: object\n",
      "\n",
      " Time needed: 5.17\n",
      "\n",
      " Test Accuracy: 96.61%\n",
      "\n",
      " Train confusion matrix: \n",
      " [[376   0   0   0   0   0   0   0   0   0]\n",
      " [  0 388   0   0   0   0   1   0   0   0]\n",
      " [  0   0 378   1   0   0   0   0   1   0]\n",
      " [  0   1   0 386   0   1   0   0   0   1]\n",
      " [  0   0   0   0 386   0   1   0   0   0]\n",
      " [  0   0   0   0   0 376   0   0   0   0]\n",
      " [  0   0   0   0   0   0 377   0   0   0]\n",
      " [  0   0   0   1   0   0   0 386   0   0]\n",
      " [  0   0   0   1   0   0   0   1 378   0]\n",
      " [  0   0   0   1   1   0   0   0   1 379]]\n",
      "\n",
      " Class Accuracy for Training Data is:\n",
      "Class 0: 100.00%\n",
      "Class 1: 99.74%\n",
      "Class 2: 99.47%\n",
      "Class 3: 99.23%\n",
      "Class 4: 99.74%\n",
      "Class 5: 100.00%\n",
      "Class 6: 100.00%\n",
      "Class 7: 99.74%\n",
      "Class 8: 99.47%\n",
      "Class 9: 99.21%\n",
      "\n",
      " Test confusion matrix: \n",
      " [[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 178   0   0   0   0   3   0   1   0]\n",
      " [  0   2 170   1   0   0   3   1   0   0]\n",
      " [  0   0   3 177   0   2   0   0   0   1]\n",
      " [  0   1   0   0 176   0   0   1   3   0]\n",
      " [  0   1   0   0   1 178   0   0   0   2]\n",
      " [  0   0   0   0   2   0 179   0   0   0]\n",
      " [  0   0   0   0   1   2   0 172   1   3]\n",
      " [  0   6   0   2   1   1   1   0 155   8]\n",
      " [  0   0   1   1   1   3   0   0   1 173]]\n",
      "\n",
      " Class Accuracy for Testing Data is:\n",
      "Class 0: 100.00%\n",
      "Class 1: 97.80%\n",
      "Class 2: 96.05%\n",
      "Class 3: 96.72%\n",
      "Class 4: 97.24%\n",
      "Class 5: 97.80%\n",
      "Class 6: 98.90%\n",
      "Class 7: 96.09%\n",
      "Class 8: 89.08%\n",
      "Class 9: 96.11%\n",
      "**********************************\n",
      "\n",
      "\n",
      " Results For Mean-Squared-Error\n",
      "**********************************\n",
      "\n",
      "For hyper-parameters:\n",
      " hidden_layers                       2\n",
      "hiden_units                        64\n",
      "num_epochs                         50\n",
      "batch_size                        128\n",
      "learning_rate                     0.9\n",
      "momentum                          0.5\n",
      "loss_func          mean_squared_error\n",
      "data_scaling              Standardize\n",
      "activation_func                  relu\n",
      "time                          6.92868\n",
      "train_loss                0.000572706\n",
      "validation_loss            0.00319363\n",
      "test_loss                   0.0054562\n",
      "train_acc                    0.998365\n",
      "validation_acc               0.981699\n",
      "test_acc                     0.966611\n",
      "Name: 1432, dtype: object\n",
      "\n",
      " Time needed: 5.94\n",
      "\n",
      " Test Accuracy: 95.94%\n",
      "\n",
      " Train confusion matrix: \n",
      " [[374   0   0   0   1   0   1   0   0   0]\n",
      " [  0 385   0   0   0   0   1   1   0   2]\n",
      " [  0   1 376   1   0   1   0   0   0   1]\n",
      " [  0   0   0 383   0   4   0   0   0   2]\n",
      " [  0   0   0   0 386   0   1   0   0   0]\n",
      " [  0   0   0   0   0 374   0   0   0   2]\n",
      " [  0   2   0   0   1   0 373   0   1   0]\n",
      " [  0   0   0   1   0   0   0 386   0   0]\n",
      " [  0   2   0   0   0   0   0   0 378   0]\n",
      " [  0   0   0   1   2   0   0   0   1 378]]\n",
      "\n",
      " Class Accuracy for Training Data is:\n",
      "Class 0: 99.47%\n",
      "Class 1: 98.97%\n",
      "Class 2: 98.95%\n",
      "Class 3: 98.46%\n",
      "Class 4: 99.74%\n",
      "Class 5: 99.47%\n",
      "Class 6: 98.94%\n",
      "Class 7: 99.74%\n",
      "Class 8: 99.47%\n",
      "Class 9: 98.95%\n",
      "\n",
      " Test confusion matrix: \n",
      " [[174   0   0   0   1   1   1   0   0   1]\n",
      " [  0 176   0   0   0   0   2   0   3   1]\n",
      " [  0   1 172   0   0   0   0   1   3   0]\n",
      " [  0   0   3 170   0   2   0   4   3   1]\n",
      " [  0   1   0   0 177   0   0   1   2   0]\n",
      " [  0   0   0   1   0 179   0   0   0   2]\n",
      " [  1   1   0   0   0   0 178   0   1   0]\n",
      " [  0   1   0   0   1   0   0 165   1  11]\n",
      " [  0   7   0   2   1   0   0   0 161   3]\n",
      " [  0   0   0   1   0   4   0   0   3 172]]\n",
      "\n",
      " Class Accuracy for Testing Data is:\n",
      "Class 0: 97.75%\n",
      "Class 1: 96.70%\n",
      "Class 2: 97.18%\n",
      "Class 3: 92.90%\n",
      "Class 4: 97.79%\n",
      "Class 5: 98.35%\n",
      "Class 6: 98.34%\n",
      "Class 7: 92.18%\n",
      "Class 8: 92.53%\n",
      "Class 9: 95.56%\n",
      "**********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if i==1:\n",
    "        top10 = top10_mse\n",
    "        print(\"\\n Results For Mean-Squared-Error\")\n",
    "        print(\"**********************************\\n\")\n",
    "    else:\n",
    "        top10 = top10_cce\n",
    "        print(\"\\n Results For Cross-Entropy\")\n",
    "        print(\"**********************************\\n\")\n",
    "        \n",
    "    if top10.iloc[0,7] == 'Standardize':\n",
    "        X_train = X_train_std\n",
    "        X_val = X_val_std\n",
    "        X_test = X_test_std\n",
    "    else:\n",
    "        X_train = X_train_norm\n",
    "        X_val = X_val_norm\n",
    "        X_test = X_test_norm\n",
    "\n",
    "\n",
    "    start = time. time()\n",
    "    if top10.iloc[0,0] == 1:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(top10.iloc[0,1], input_dim=64, activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "    elif top10.iloc[0,0] == 2:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(top10.iloc[0,1], input_dim=64, activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(top10.iloc[0,1], activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "    elif top10.iloc[0,0] == 3:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(top10.iloc[0,1], input_dim=64, activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(top10.iloc[0,1], activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(top10.iloc[0,1], activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "    else:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(top10.iloc[0,1], input_dim=64, activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(top10.iloc[0,1], activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(top10.iloc[0,1], activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(top10.iloc[0,1], activation=top10.iloc[0,8]))\n",
    "        model.add(Dense(ccat, activation='softmax'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=200)\n",
    "    mc = ModelCheckpoint('best_model', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "\n",
    "    optimizer1 = optimizers.SGD(lr=top10.iloc[0,4], momentum=top10.iloc[0,5])\n",
    "    model.compile(optimizer=optimizer1, loss=top10.iloc[0,6], metrics=['accuracy'])\n",
    "    fit1 = model.fit(X_train,y_train, batch_size=top10.iloc[0,3], epochs=top10.iloc[0,2], \n",
    "                     validation_data=(X_val,y_val), callbacks=[es, mc], verbose = 0)\n",
    "    fit = load_model('best_model')\n",
    "    end = time.time()\n",
    "\n",
    "    train_accuracy = fit.evaluate(X_train, y_train, verbose=0)\n",
    "    val_accuracy = fit.evaluate(X_val, y_val, verbose=0)\n",
    "    test_accuracy = fit.evaluate(X_test, y_test, verbose=0)\n",
    "    final_res = [end-start, train_accuracy[0], val_accuracy[0], test_accuracy[0], \n",
    "                 train_accuracy[1], val_accuracy[1], test_accuracy[1]]\n",
    "    \n",
    "    if top10.iloc[0,7] == 'Standardize':\n",
    "        X_train11 = X_tr_std\n",
    "        X_test = X_test_std\n",
    "        y_train11 = y_train1\n",
    "    else:\n",
    "        X_train11 = X_tr_norm\n",
    "        X_test = X_test_norm\n",
    "        y_train11 = y_train1\n",
    "\n",
    "    print(\"For hyper-parameters:\\n\",top10.iloc[0,:])\n",
    "    print(\"\\n Time needed: %.2f\" % (end-start))\n",
    "    scores = fit.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"\\n Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "    A = fit.predict(X_train11)\n",
    "    cm = confusion_matrix(y_train11.argmax(axis=1), A.argmax(axis=1))\n",
    "    print(\"\\n Train confusion matrix: \\n\", cm)\n",
    "    acc_train = np.diagonal(cm)/cm.sum(axis=1)\n",
    "    print(\"\\n Class Accuracy for Training Data is:\")\n",
    "    for i in range(10):\n",
    "        print('Class %d: %.2f%%' %(i, acc_train[i]*100))\n",
    "\n",
    "    A = fit.predict(X_test)\n",
    "    cm = confusion_matrix(y_test.argmax(axis=1), A.argmax(axis=1))\n",
    "    print(\"\\n Test confusion matrix: \\n\", cm)\n",
    "    acc_test = np.diagonal(cm)/cm.sum(axis=1)\n",
    "    print(\"\\n Class Accuracy for Testing Data is:\")\n",
    "    for i in range(10):\n",
    "        print('Class %d: %.2f%%' %(i, acc_test[i]*100))\n",
    "    print(\"**********************************\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the time distribution, though both mean-squared-error and cross-entropy look like have the same distribution, but cross-entropy has higher mean and variance compare to MSE. \n",
    "\n",
    "However, based on test accuracy distributions for MSE and cross-entropy, clearly cross-entropy has higher test accuracy than MSE loss function. The average test accuracy for all combinations of hyper-parameter is higher for cross-entropy loss function compare to MSE and lower variance for cross-entropy than MSE. This indicates that for multi-category classification, it is better to use cross-entropy compare to MSE loss function.\n",
    "\n",
    "It is found that using cross-entropy loss function with 2 hidden layers, 64 units, number of epochs 50, batch size 128, learning rate 0.9 and momentum 0.3 has the highest test accuracy (around 96.00%). Note that, this model was fitted based on only 1-fold cross validation with no repeated sample. It might be different if we use repeated $k$ fold cross validation.\n",
    "\n",
    "Training accuracy for all classes are almost 100%. However, test accuracy for all classes are around 96% for cross-entropy loss function which are higher than the MSE. Class 0 has the highest test accuracy and class 8 has the lowest accuracy for cross-entropy loss function. Also, similar pattern has been found for the MSE loss function with comparatively lower accuracy than cross-entropy. Overall classication accuracy, class accuracy, and confusion matrix for both training and testing data are given in above tables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important References:\n",
    "\n",
    "1. https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
    "\n",
    "2. https://towardsdatascience.com/building-a-deep-learning-model-using-keras-1548ca149d37\n",
    "\n",
    "3. https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "4. https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "\n",
    "5. https://towardsdatascience.com/convolutional-neural-networks-for-beginners-practical-guide-with-python-and-keras-dc688ea90dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonCPU",
   "language": "python",
   "name": "pythoncpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
