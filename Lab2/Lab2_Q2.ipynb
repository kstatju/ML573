{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> ComS 573     </center></h1>\n",
    "<h1><center> Lab 2 </center></h1>\n",
    "<h1><center> Kanak Choudhury </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, I have used the following parameter combinations\n",
    "    \n",
    "    hid_layer = [2,3]\n",
    "    num_epochs = [80, 100, 120]\n",
    "    btch_size = [128, 200]\n",
    "    learning_rate = [0.05, 0.1, 0.2]\n",
    "    momentum = [.5, 0.9, 1]\n",
    "    los = ['categorical_crossentropy']\n",
    "    scale = ['Standardize', 'Normalize']\n",
    "    activ = ['relu']\n",
    "    filters = [64, 32]\n",
    "    kernel_size = [(3,3), (4, 4)]\n",
    "\n",
    "Also used 80% - 20% training - validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.1\n",
      "matplotlib 3.1.3\n",
      "keras 2.3.1\n",
      "re 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import matplotlib\n",
    "import keras\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "print('python ' +sys.version)\n",
    "print('numpy '+ np.__version__)\n",
    "print('pandas '+ pd.__version__)\n",
    "print('sklearn '+ sklearn.__version__)\n",
    "print('matplotlib '+ matplotlib.__version__)\n",
    "print('keras '+ keras.__version__)\n",
    "print('re '+ re.__version__)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = 'D:/ISU/COMS 573 - Machine Learning/HW/Lab2/'\n",
    "\n",
    "train_model = False\n",
    "\n",
    "df_tr = pd.read_csv(path+'optdigits.tra',header=None)\n",
    "X_tr, y_tr = df_tr.loc[:,0:63], df_tr.loc[:,64]\n",
    "ccat = y_tr.unique().size\n",
    "\n",
    "df_ts = pd.read_csv(path+'optdigits.tes',header=None)\n",
    "X_ts,  y_ts  = df_ts.loc[:,0:63],  df_ts.loc[:,64]\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "normalizer = Normalizer().fit(X_tr)\n",
    "\n",
    "X_tr_std = scaler.transform(X_tr)\n",
    "X_tr_norm = normalizer.transform(X_tr)\n",
    "\n",
    "\n",
    "split = 0.8\n",
    "size = np.shape(X_tr)\n",
    "nsplit = int(np.floor(split*size[0]))\n",
    "\n",
    "y_train1 = np_utils.to_categorical(y_tr, ccat)\n",
    "y_train = y_train1[0:nsplit,:];\n",
    "y_val = y_train1[nsplit:size[0],:];\n",
    "y_test = np_utils.to_categorical(y_ts, ccat)\n",
    "\n",
    "\n",
    "X_train_std = X_tr_std[0:nsplit,:];\n",
    "X_val_std = X_tr_std[nsplit:size[0],:];\n",
    "X_test_std = scaler.transform(X_ts)\n",
    "\n",
    "X_train_std = X_train_std.reshape(-1, 8, 8, 1)\n",
    "X_val_std = X_val_std.reshape(-1, 8, 8, 1)\n",
    "X_test_std = X_test_std.reshape(-1, 8, 8, 1)\n",
    "\n",
    "\n",
    "\n",
    "X_train_norm = X_tr_norm[0:nsplit,:];\n",
    "X_val_norm = X_tr_norm[nsplit:size[0],:];\n",
    "X_test_norm = normalizer.transform(X_ts)\n",
    "\n",
    "X_train_norm = X_train_norm.reshape(-1, 8, 8, 1)\n",
    "X_val_norm = X_val_norm.reshape(-1, 8, 8, 1)\n",
    "X_test_norm = X_test_norm.reshape(-1, 8, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skiped model fit\n"
     ]
    }
   ],
   "source": [
    "if train_model: \n",
    "    hid_layer = [2,3]\n",
    "    num_epochs = [80, 100, 120]\n",
    "    btch_size = [128, 200]\n",
    "    learning_rate = [0.05, 0.1, 0.2]\n",
    "    momentum = [.5, 0.9, 1]\n",
    "    los = ['categorical_crossentropy']\n",
    "    scale = ['Standardize', 'Normalize']\n",
    "    activ = ['relu']\n",
    "    filters = [64, 32]\n",
    "    kernel_size = [(3,3), (4, 4)]\n",
    "\n",
    "\n",
    "    def expand_grid(dictionary):\n",
    "       return pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "\n",
    "    dictionary = {'hidden_layers': hid_layer,\n",
    "                  'filters': filters,\n",
    "                  'num_epochs': num_epochs, \n",
    "                  'batch_size': btch_size,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'momentum': momentum,\n",
    "                  'loss_func': los,\n",
    "                  'data_scaling': scale,\n",
    "                  'activation_func': activ,\n",
    "                  'kernel_size': kernel_size}\n",
    "\n",
    "    prem1 = expand_grid(dictionary)\n",
    "    prem1 = prem1[~((prem1['activation_func'] == 'tanh') & (prem1['loss_func'] == 'mean_squared_error'))]\n",
    "    prem1['time'] = np.NaN\n",
    "    prem1['train_loss'] = np.NaN\n",
    "    prem1['validation_loss'] = np.NaN\n",
    "    prem1['test_loss'] = np.NaN\n",
    "    prem1['train_acc'] = np.NaN\n",
    "    prem1['validation_acc'] = np.NaN\n",
    "    prem1['test_acc'] = np.NaN\n",
    "    size_prem1 = prem1.shape\n",
    "    print(prem1.head())\n",
    "    \n",
    "    ll = 0 \n",
    "    for j in range(0,2):\n",
    "        if j == 0:\n",
    "            X_train = X_train_std\n",
    "            X_val = X_val_std\n",
    "            X_test = X_test_std\n",
    "            listind = prem1[prem1['data_scaling'] == 'Standardize'].index.tolist()\n",
    "        else:\n",
    "            X_train = X_train_norm\n",
    "            X_val = X_val_norm\n",
    "            X_test = X_test_norm\n",
    "            listind = prem1[prem1['data_scaling'] == 'Normalize'].index.tolist()\n",
    "\n",
    "        for i in listind:\n",
    "            try:\n",
    "                start = time. time()\n",
    "                if prem1.iloc[i,0] == 1:\n",
    "                    model = Sequential()\n",
    "                    model.add(Convolution2D(filters = 64, kernel_size= prem1.iloc[i,9], \n",
    "                                            input_shape=(8,8,1), activation='relu', padding='valid')) \n",
    "                    model.add(MaxPooling2D(pool_size=(2,2), padding='valid')) \n",
    "                    model.add(Dropout(0.3))\n",
    "                    model.add(Flatten())\n",
    "                    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "                elif prem1.iloc[i,0] == 2:\n",
    "                    model = Sequential()\n",
    "                    model.add(Convolution2D(filters = 64, kernel_size= prem1.iloc[i,9], \n",
    "                                            input_shape=(8,8,1), activation='relu', padding='valid')) \n",
    "                    model.add(Convolution2D(filters = prem1.iloc[i,1], kernel_size= prem1.iloc[i,9], padding='valid'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2,2), padding='valid')) \n",
    "                    model.add(Dropout(0.3))\n",
    "                    model.add(Flatten())\n",
    "                    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "                else:\n",
    "                    model = Sequential()            \n",
    "                    model.add(Convolution2D(filters = 64, kernel_size= prem1.iloc[i,9], \n",
    "                                            input_shape=(8,8,1), activation='relu', padding='valid')) \n",
    "                    model.add(Convolution2D(filters = prem1.iloc[i,1], kernel_size= prem1.iloc[i,9], padding='valid'))\n",
    "                    model.add(Convolution2D(filters = prem1.iloc[i,1], kernel_size= prem1.iloc[i,9], padding='valid'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2,2), padding='valid')) \n",
    "                    model.add(Dropout(0.3))\n",
    "                    model.add(Flatten())\n",
    "                    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "                es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=200)\n",
    "                mc = ModelCheckpoint('best_model', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "\n",
    "\n",
    "                optimizer1 = optimizers.SGD(lr=prem1.iloc[i,4], momentum=prem1.iloc[i,5])\n",
    "                model.compile(optimizer=optimizer1, loss=prem1.iloc[i,6], metrics=['accuracy'])\n",
    "                fit1 = model.fit(X_train,y_train, batch_size=prem1.iloc[i,3], epochs=prem1.iloc[i,2], \n",
    "                                 validation_data=(X_val,y_val), callbacks=[es, mc], verbose = 0)\n",
    "                fit = load_model('best_model')\n",
    "                end = time.time()\n",
    "                train_accuracy = fit.evaluate(X_train, y_train, verbose=0)\n",
    "                val_accuracy = fit.evaluate(X_val, y_val, verbose=0)\n",
    "                test_accuracy = fit.evaluate(X_test, y_test, verbose=0)\n",
    "                prem1.iloc[i, 10:17] = [end-start, train_accuracy[0], val_accuracy[0], test_accuracy[0], \n",
    "                                      train_accuracy[1], val_accuracy[1], test_accuracy[1]]\n",
    "\n",
    "\n",
    "                del model, es, mc, optimizer1, fit, fit1\n",
    "                gc.collect()\n",
    "            except:\n",
    "                pass\n",
    "            finally:\n",
    "                ll = ll+1\n",
    "                sys.stdout.write(\"\\r Progress: %.2f%%\" %round(float(ll)/size_prem1[0]*100,2))\n",
    "                sys.stdout.flush()\n",
    "else:\n",
    "    print('skiped model fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best 10 hyper-parameter combination for Cross-Entropy:\n",
      "      hidden_layers  filters  num_epochs  batch_size  learning_rate  momentum  \\\n",
      "509              3       64         100         128           0.20       0.5   \n",
      "487              3       64          80         128           0.05       0.9   \n",
      "521              3       64         120         128           0.05       0.9   \n",
      "579              3       32         120         200           0.10       0.5   \n",
      "580              3       32         120         200           0.10       0.9   \n",
      "547              3       32          80         200           0.10       0.5   \n",
      "556              3       32         100         128           0.10       0.5   \n",
      "332              2       64         100         200           0.10       0.9   \n",
      "355              2       64         120         128           0.20       0.5   \n",
      "374              2       64         120         200           0.20       0.9   \n",
      "\n",
      "                    loss_func data_scaling activation_func kernel_size  \\\n",
      "509  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "487  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "521  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "579  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "580  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "547  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "556  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "332  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "355  categorical_crossentropy  Standardize            relu      (4, 4)   \n",
      "374  categorical_crossentropy  Standardize            relu      (3, 3)   \n",
      "\n",
      "         time  train_loss  validation_loss  test_loss  train_acc  \\\n",
      "509  104.5165      0.0000           0.0481     0.0407     1.0000   \n",
      "487   75.6567      0.0003           0.0335     0.0501     1.0000   \n",
      "521  119.9278      0.0001           0.0758     0.0475     1.0000   \n",
      "579   85.3661      0.0006           0.0615     0.0466     1.0000   \n",
      "580   81.9683      0.0001           0.0906     0.0623     1.0000   \n",
      "547   59.1002      0.0020           0.0466     0.0584     0.9997   \n",
      "556   81.4093      0.0028           0.0394     0.0414     0.9993   \n",
      "332   71.7168      0.0001           0.0537     0.0632     1.0000   \n",
      "355   54.8639      0.0002           0.0415     0.0633     1.0000   \n",
      "374   67.5542      0.0000           0.0308     0.0681     1.0000   \n",
      "\n",
      "     validation_acc  test_acc  \n",
      "509          0.9922    0.9900  \n",
      "487          0.9948    0.9878  \n",
      "521          0.9895    0.9878  \n",
      "579          0.9908    0.9878  \n",
      "580          0.9935    0.9872  \n",
      "547          0.9935    0.9866  \n",
      "556          0.9935    0.9866  \n",
      "332          0.9935    0.9861  \n",
      "355          0.9935    0.9861  \n",
      "374          0.9961    0.9861  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train_model:\n",
    "    prem1.to_csv (path+'res_2.csv', index = False, header=True)\n",
    "    prem = prem1\n",
    "else:\n",
    "    prem = pd.read_csv(path+'res_2.csv',header=0)\n",
    "    prem.head()\n",
    "\n",
    "    kk1 = []\n",
    "    for i in range(prem.shape[0]):\n",
    "        kk1.append(tuple(map(int, prem.iloc[i,9].replace('(', '').replace(')', '').replace(' ', '').split(','))))\n",
    "    prem['kernel_size'] = kk1\n",
    "\n",
    "top10_cce = prem[prem['loss_func'] == 'categorical_crossentropy'].nlargest(10,'test_acc')\n",
    "print('\\n Best 10 hyper-parameter combination for Cross-Entropy:\\n', round(top10_cce, 4))\n",
    "\n",
    "\n",
    "plt.hist(prem.iloc[:,10],  density=True, alpha=0.5, label=['CNN'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of time to fit models')\n",
    "# plt.xlim(0, 200)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(prem.iloc[:,16],\n",
    "         density=True, alpha=0.5, label=['CNN'])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Distribution of test accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and Variance of fitted time:\n",
      " CNN: Mean = 46.11, var = 655.43\n",
      "\n",
      "Mean and Variance of test accuracy:\n",
      " CNN: Mean = 0.8302, var = 0.0736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aaa = prem.iloc[:,10]\n",
    "print(\"Mean and Variance of fitted time:\\n CNN: Mean = %.2f, \\\n",
    "var = %.2f\\n\" %(np.mean(aaa), np.var(aaa)))\n",
    "\n",
    "aaa = prem.iloc[:,16]\n",
    "print(\"Mean and Variance of test accuracy:\\n CNN: Mean = %.4f, \\\n",
    "var = %.4f\\n\" %(np.mean(aaa), np.var(aaa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results For CNN\n",
      "******************************************\n",
      "\n",
      "For hyper-parameters:\n",
      " hidden_layers                             3\n",
      "filters                                  64\n",
      "num_epochs                              100\n",
      "batch_size                              128\n",
      "learning_rate                           0.2\n",
      "momentum                                0.5\n",
      "loss_func          categorical_crossentropy\n",
      "data_scaling                    Standardize\n",
      "activation_func                        relu\n",
      "kernel_size                          (3, 3)\n",
      "time                                104.516\n",
      "train_loss                      3.74972e-05\n",
      "validation_loss                   0.0481159\n",
      "test_loss                         0.0407299\n",
      "train_acc                                 1\n",
      "validation_acc                     0.992157\n",
      "test_acc                           0.989983\n",
      "Name: 509, dtype: object\n",
      "\n",
      " Time needed: 67.97\n",
      "\n",
      " Test Accuracy: 98.55%\n",
      "\n",
      " Train confusion matrix: \n",
      " [[376   0   0   0   0   0   0   0   0   0]\n",
      " [  0 389   0   0   0   0   0   0   0   0]\n",
      " [  0   0 380   0   0   0   0   0   0   0]\n",
      " [  0   0   0 388   0   0   0   0   0   1]\n",
      " [  0   0   0   0 386   0   1   0   0   0]\n",
      " [  0   0   0   0   0 376   0   0   0   0]\n",
      " [  0   0   0   0   0   0 377   0   0   0]\n",
      " [  0   0   0   1   0   0   0 386   0   0]\n",
      " [  0   1   0   0   0   0   0   0 378   1]\n",
      " [  0   0   0   0   0   0   0   0   0 382]]\n",
      "\n",
      " Class Accuracy for Training Data is:\n",
      "Class 0: 100.00%\n",
      "Class 1: 100.00%\n",
      "Class 2: 100.00%\n",
      "Class 3: 99.74%\n",
      "Class 4: 99.74%\n",
      "Class 5: 100.00%\n",
      "Class 6: 100.00%\n",
      "Class 7: 99.74%\n",
      "Class 8: 99.47%\n",
      "Class 9: 100.00%\n",
      "\n",
      " Test confusion matrix: \n",
      " [[177   0   0   0   1   0   0   0   0   0]\n",
      " [  0 182   0   0   0   0   0   0   0   0]\n",
      " [  0   1 176   0   0   0   0   0   0   0]\n",
      " [  0   0   0 180   0   1   0   0   0   2]\n",
      " [  0   2   0   0 179   0   0   0   0   0]\n",
      " [  0   0   0   0   1 177   1   0   0   3]\n",
      " [  0   0   0   0   2   1 178   0   0   0]\n",
      " [  0   0   0   0   0   0   0 177   0   2]\n",
      " [  0   1   0   1   1   0   0   0 170   1]\n",
      " [  0   0   0   1   1   1   0   0   2 175]]\n",
      "\n",
      " Class Accuracy for Testing Data is:\n",
      "Class 0: 99.44%\n",
      "Class 1: 100.00%\n",
      "Class 2: 99.44%\n",
      "Class 3: 98.36%\n",
      "Class 4: 98.90%\n",
      "Class 5: 97.25%\n",
      "Class 6: 98.34%\n",
      "Class 7: 98.88%\n",
      "Class 8: 97.70%\n",
      "Class 9: 97.22%\n",
      "**********************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10 = top10_cce\n",
    "print(\"\\n Results For CNN\")\n",
    "print(\"******************************************\\n\")\n",
    "\n",
    "\n",
    "if top10.iloc[0,7] == 'Standardize':\n",
    "    X_train = X_train_std\n",
    "    X_val = X_val_std\n",
    "    X_test = X_test_std\n",
    "else:\n",
    "    X_train = X_train_norm\n",
    "    X_val = X_val_norm\n",
    "    X_test = X_test_norm\n",
    "\n",
    "\n",
    "start = time. time()\n",
    "if top10.iloc[0,0] == 1:\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters = 64, kernel_size= top10.iloc[0,9], \n",
    "                            input_shape=(8,8,1), activation='relu', padding='valid')) \n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='valid')) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "elif top10.iloc[0,0] == 2:\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters = 64, kernel_size= top10.iloc[0,9], \n",
    "                            input_shape=(8,8,1), activation='relu', padding='valid')) \n",
    "    model.add(Convolution2D(filters = top10.iloc[0,1], kernel_size= top10.iloc[0,9], padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='valid')) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "else:\n",
    "    model = Sequential()            \n",
    "    model.add(Convolution2D(filters = 64, kernel_size= top10.iloc[0,9], \n",
    "                            input_shape=(8,8,1), activation='relu', padding='valid')) \n",
    "    model.add(Convolution2D(filters = top10.iloc[0,1], kernel_size= top10.iloc[0,9], padding='valid'))\n",
    "    model.add(Convolution2D(filters = top10.iloc[0,1], kernel_size= top10.iloc[0,9], padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='valid')) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=200)\n",
    "mc = ModelCheckpoint('best_model', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "\n",
    "\n",
    "optimizer1 = optimizers.SGD(lr=top10.iloc[0,4], momentum=top10.iloc[0,5])\n",
    "model.compile(optimizer=optimizer1, loss=top10.iloc[0,6], metrics=['accuracy'])\n",
    "fit1 = model.fit(X_train,y_train, batch_size=top10.iloc[0,3], epochs=top10.iloc[0,2], \n",
    "                 validation_data=(X_val,y_val), callbacks=[es, mc], verbose = 0)\n",
    "fit = load_model('best_model')\n",
    "end = time.time()\n",
    "train_accuracy = fit.evaluate(X_train, y_train, verbose=0)\n",
    "val_accuracy = fit.evaluate(X_val, y_val, verbose=0)\n",
    "test_accuracy = fit.evaluate(X_test, y_test, verbose=0)\n",
    "final_res = [end-start, train_accuracy[0], val_accuracy[0], test_accuracy[0], \n",
    "                      train_accuracy[1], val_accuracy[1], test_accuracy[1]]\n",
    "\n",
    "if top10.iloc[0,7] == 'Standardize':\n",
    "    X_train11 = X_tr_std.reshape(-1, 8, 8, 1)\n",
    "    X_test = X_test_std\n",
    "    y_train11 = y_train1\n",
    "else:\n",
    "    X_train11 = X_tr_norm.reshape(-1, 8, 8, 1)\n",
    "    X_test = X_test_norm\n",
    "    y_train11 = y_train1\n",
    "\n",
    "print(\"For hyper-parameters:\\n\",top10.iloc[0,:])\n",
    "print(\"\\n Time needed: %.2f\" % (end-start))\n",
    "scores = fit.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\n Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "A = fit.predict(X_train11)\n",
    "cm = confusion_matrix(y_train11.argmax(axis=1), A.argmax(axis=1))\n",
    "print(\"\\n Train confusion matrix: \\n\", cm)\n",
    "acc_train = np.diagonal(cm)/cm.sum(axis=1)\n",
    "print(\"\\n Class Accuracy for Training Data is:\")\n",
    "for i in range(10):\n",
    "    print('Class %d: %.2f%%' %(i, acc_train[i]*100))\n",
    "\n",
    "A = fit.predict(X_test)\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), A.argmax(axis=1))\n",
    "print(\"\\n Test confusion matrix: \\n\", cm)\n",
    "acc_test = np.diagonal(cm)/cm.sum(axis=1)\n",
    "print(\"\\n Class Accuracy for Testing Data is:\")\n",
    "for i in range(10):\n",
    "    print('Class %d: %.2f%%' %(i, acc_test[i]*100))\n",
    "print(\"**********************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the time distribution, CNN takes longer time than fully connected feed-forward networks. However, the time distribution for CNN is less skewed than fully connected feed-forward networks. \n",
    "\n",
    "Based on test accuracy distributions, overall accuracy for test data using CNN is higher (about 98%) than the fully connected feed-forward networks and the variance is also lower for these hyper-parameter combinations.\n",
    "\n",
    "It is found that using CNN with 3 hidden layers, 64 units, number of epochs 100, batch size 128, learning rate 0.2, momentum 0.5 and kernel size (3,3) has the highest test accuracy (about 98.00%) which is higher than the fully connected feed forward networks. Note that, this model was fitted based on only 1-fold cross validation with no repeated sample. It might be different if we use repeated $k$ fold cross validation.\n",
    "\n",
    "Training accuracy for all classes are almost 100%. However, test accuracy for all classes are around 98%. Class 0 and 1 have the highest test accuracy (about 100%) and class 8 has the lowest accuracy (about 97%) which is much higher than the fully connected feed forward networks. Overall classiﬁcation accuracy, class accuracy, and confusion matrix for both training and testing data are given in above tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important References:\n",
    "\n",
    "1. https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
    "\n",
    "2. https://towardsdatascience.com/building-a-deep-learning-model-using-keras-1548ca149d37\n",
    "\n",
    "3. https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "4. https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "\n",
    "5. https://towardsdatascience.com/convolutional-neural-networks-for-beginners-practical-guide-with-python-and-keras-dc688ea90dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonCPU",
   "language": "python",
   "name": "pythoncpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
